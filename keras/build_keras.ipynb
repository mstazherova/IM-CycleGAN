{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.layers import BatchNormalization, Conv2D, ZeroPadding2D, Input, Dropout, Concatenate\n",
    "from keras.layers import Conv2DTranspose, UpSampling2D, Activation, Add, Lambda, Cropping2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.activations import relu\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from PIL import Image\n",
    "import glob\n",
    "import numpy as np\n",
    "from IPython.display import display, clear_output\n",
    "from random import shuffle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "\n",
    "config = tf.ConfigProto(log_device_placement=True)\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "config.gpu_options.allow_growth = True \n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchnorm():\n",
    "    return BatchNormalization(momentum=0.9, axis=3, epsilon=1e-5, gamma_initializer = RandomNormal(1., 0.02))\n",
    "\n",
    "\n",
    "def conv2d(x, *a, **k):\n",
    "    return Conv2D(kernel_initializer = RandomNormal(0, 0.02), *a, **k)(x)\n",
    "\n",
    "\n",
    "def conv_block(x, filters, size, stride=(2, 2), has_norm_layer=True, use_norm_instance=False,\n",
    "               has_activation_layer=True, use_leaky_relu=False, padding='same'):\n",
    "    x = conv2d(x, filters, (size, size), strides=stride, padding=padding)\n",
    "    if has_norm_layer:\n",
    "        if not use_norm_instance:\n",
    "            x = batchnorm()(x)\n",
    "        else:\n",
    "            x = InstanceNormalization(axis=1)(x)\n",
    "    if has_activation_layer:\n",
    "        if not use_leaky_relu:\n",
    "            x = Activation('relu')(x)\n",
    "        else:\n",
    "            x = LeakyReLU(alpha=0.2)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_block(x, filters=256, padding='same'):\n",
    "    y = conv2d(x, filters, kernel_size=3, strides=1, padding=padding)\n",
    "    y = LeakyReLU(alpha=0.2)(x)\n",
    "    y = conv2d(x, filters, kernel_size=3, strides=1, padding=padding)\n",
    "    \n",
    "    return Add()([y, x])\n",
    "\n",
    "\n",
    "def up_block(x, filters, size, use_norm_instance=False):\n",
    "    x = Conv2DTranspose(filters, kernel_size=size, strides=2, padding='same',\n",
    "                            use_bias=True if use_norm_instance else False,\n",
    "                            kernel_initializer=RandomNormal(0, 0.02))(x)\n",
    "    x = batchnorm()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generator(image_size=256, channels=3, res_blocks=6):\n",
    "#     \"\"\"Builds the generator that consists of an encoder, \n",
    "#     a transformer and a decoder.\"\"\"\n",
    "#     inputs = Input(shape=(None, None, channels))\n",
    "#     x = inputs\n",
    "    \n",
    "#     # Encoder\n",
    "#     x = conv2d(x, 64, kernel_size=7, strides=1, padding='same')\n",
    "#     x = conv2d(x, 128, kernel_size=3, strides=2, padding='same')\n",
    "#     x = conv2d(x, 256, kernel_size=3, strides=2, padding='same')\n",
    "    \n",
    "#     # Transformer\n",
    "#     for i in range(res_blocks):\n",
    "#         x = resnet_block(x)\n",
    "        \n",
    "#     # Decoder\n",
    "#     x = Conv2DTranspose(128, kernel_size=3, strides=2, padding='same')(x)\n",
    "#     x = batchnorm()(x)\n",
    "#     x = Activation('relu')(x)\n",
    "#     x = Conv2DTranspose(64, kernel_size=3, strides=2, padding='same')(x)\n",
    "    \n",
    "#     x = conv2d(x, 3, (7, 7), activation='tanh', strides=(1, 1) ,padding='same')    \n",
    "#     outputs = x\n",
    "    \n",
    "#     return Model(inputs=inputs, outputs=[outputs])\n",
    "def generator(image_size=256, channels=3, res_blocks=6):\n",
    "    inputs = Input(shape=(image_size, image_size, channels))\n",
    "    x = inputs\n",
    "    \n",
    "    # Encoder\n",
    "    x = conv_block(x, 64, 7, (1, 1))\n",
    "    x = conv_block(x, 128, 3, (2, 2))\n",
    "    x = conv_block(x, 256, 3, (2, 2))\n",
    "    \n",
    "    # Transformer\n",
    "    for i in range(res_blocks):\n",
    "        x = res_block(x)\n",
    "        \n",
    "    # Decoder    \n",
    "    x = up_block(x, 128, 3)\n",
    "    x = up_block(x, 64, 3)\n",
    "    \n",
    "    x = conv2d(3, (7, 7), activation='tanh', strides=(1, 1) ,padding='same')(x)    \n",
    "    outputs = x\n",
    "    return Model(inputs=inputs, outputs=[outputs])\n",
    "\n",
    "\n",
    "def unet_generator(isize=256, nc_in=3, nc_out=3, ngf=64, fixed_input_size=True):    \n",
    "    max_nf = 8*ngf    \n",
    "    def block(x, s, nf_in, use_batchnorm=True, nf_out=None, nf_next=None):\n",
    "        assert s>=2 and s%2==0\n",
    "        if nf_next is None:\n",
    "            nf_next = min(nf_in*2, max_nf)\n",
    "        if nf_out is None:\n",
    "            nf_out = nf_in\n",
    "        x = conv2d(x, nf_next, kernel_size=4, strides=2, use_bias=(not (use_batchnorm and s>2)),\n",
    "                   padding=\"same\", name = 'conv_{0}'.format(s))\n",
    "        if s>2:\n",
    "            if use_batchnorm:\n",
    "                x = batchnorm()(x, training=1)\n",
    "            x2 = LeakyReLU(alpha=0.2)(x)\n",
    "            x2 = block(x2, s//2, nf_next)\n",
    "            x = Concatenate(axis=-1)([x, x2])            \n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Conv2DTranspose(nf_out, kernel_size=4, strides=2, use_bias=not use_batchnorm,\n",
    "                            kernel_initializer = RandomNormal(0, 0.02),          \n",
    "                            name = 'convt.{0}'.format(s))(x)        \n",
    "        x = Cropping2D(1)(x)\n",
    "        if use_batchnorm:\n",
    "            x = batchnorm()(x, training=1)  # training parameter?\n",
    "        if s <=8:\n",
    "            x = Dropout(0.5)(x, training=1)\n",
    "        return x\n",
    "    \n",
    "    s = isize if fixed_input_size else None\n",
    "   \n",
    "    y = inputs = Input(shape=(s, s, nc_in))        \n",
    "    y = block(y, isize, nc_in, False, nf_out=nc_out, nf_next=ngf)\n",
    "    y = Activation('tanh')(y)\n",
    "    return Model(inputs=inputs, outputs=[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def discriminator(image_size=256, channels=3, fl_filters=64, hidden_layers=3):\n",
    "#     inputs = Input(shape=(None, None, channels))\n",
    "#     x = inputs\n",
    "\n",
    "#     x = ZeroPadding2D(padding=(1, 1))(x)\n",
    "#     x = conv2d(x, fl_filters, kernel_size=4, strides=2, padding='valid')\n",
    "#     x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "#     x = ZeroPadding2D(padding=(1, 1))(x)\n",
    "#     for i in range(1, hidden_layers + 1):\n",
    "#         nf = 2 ** i * fl_filters\n",
    "#         x = conv2d(x, fl_filters, kernel_size=4, strides=2, padding='valid')\n",
    "#         x = LeakyReLU(alpha=0.2)(x)\n",
    "#         x = ZeroPadding2D(padding=(1, 1))(x)\n",
    "#     x = conv2d(x, 1, kernel_size=4, activation='sigmoid', strides=(1, 1))\n",
    "#     outputs = x\n",
    "    \n",
    "#     return Model(inputs=[inputs], outputs=outputs)\n",
    "\n",
    "\n",
    "def discriminator(channels=3, ndf=64, hidden_layers=3, channel_first=False):\n",
    "    \"\"\"ndf: filters of the first layer\"\"\"    \n",
    "    inputs = Input(shape=(None, None, channels))\n",
    "    x = inputs\n",
    "    x = conv2d(x, ndf, kernel_size=4, strides=2, padding=\"same\")\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    for layer in range(1, hidden_layers):        \n",
    "        out_feat = 2 ** layer * ndf \n",
    "        x = conv2d(x, out_feat, kernel_size=4, strides=2, padding=\"same\", use_bias=False)\n",
    "        x = batchnorm()(x, training=1) # training parameter?       \n",
    "        x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    out_feat = ndf * 2 ** hidden_layers \n",
    "    x = ZeroPadding2D(padding=(1, 1))(x)\n",
    "    x = conv2d(x, out_feat, kernel_size=4,  use_bias=False) \n",
    "    x = batchnorm()(x, training=1)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    # final layer\n",
    "    x = ZeroPadding2D(padding=(1, 1))(x)\n",
    "    x = conv2d(x, 1, kernel_size=4, activation = \"sigmoid\")   \n",
    "    return Model(inputs=[inputs], outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(output, target):\n",
    "    return K.mean(K.abs(K.square(output-target)))\n",
    "\n",
    "def disc_loss(disc, real, fake):\n",
    "    d_real = disc([real])  # input  -> [0, 1].  Prob that real input is real.\n",
    "    d_fake = disc([fake])  # generated sample -> [0, 1]. Prob that generated output is real.\n",
    "    d_loss_real = mse(d_real, K.ones_like(d_real))\n",
    "    d_loss_fake = mse(d_fake, K.zeros_like(d_fake))\n",
    "    d_loss = (d_loss_real + d_loss_fake)/2\n",
    "    \n",
    "    return d_loss\n",
    "\n",
    "def cycle_loss(reconstructed, real):\n",
    "    return K.mean(K.abs(reconstructed - real))\n",
    "\n",
    "def gen_loss(disc, fake):\n",
    "    d_gen = disc([fake])\n",
    "    return mse(d_gen, K.ones_like(d_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_a = discriminator()\n",
    "d_b = discriminator()\n",
    "g_a = generator()\n",
    "g_b = generator()\n",
    "real_a = g_b.inputs[0]\n",
    "fake_b = g_b.outputs[0]\n",
    "rec_a = g_a([fake_b])\n",
    "real_b = g_a.inputs[0]\n",
    "fake_a = g_a.outputs[0]\n",
    "rec_b = g_b([fake_a])\n",
    "\n",
    "d_a_loss = disc_loss(d_a, real_a, fake_a)\n",
    "d_b_loss = disc_loss(d_b, real_b, fake_b)\n",
    "g_a_loss = gen_loss(d_a, fake_a)\n",
    "g_b_loss = gen_loss(d_b, fake_b)\n",
    "\n",
    "cycleA_generate = K.function([real_a], [fake_b, rec_a])\n",
    "cycleB_generate = K.function([real_b], [fake_a, rec_b])\n",
    "\n",
    "cycle_loss = cycle_loss(rec_a, real_a) + cycle_loss(rec_b, real_b)\n",
    "g_total_a = g_a_loss + 10*cycle_loss\n",
    "g_total_b = g_b_loss + 10*cycle_loss\n",
    "g_total = g_a_loss + g_b_loss + 10*cycle_loss\n",
    "d_total = d_a_loss + d_b_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_d = d_a.trainable_weights + d_b.trainable_weights\n",
    "weights_g = g_a.trainable_weights + g_b.trainable_weights\n",
    "\n",
    "training_updates = Adam(lr=2e-4, beta_1=0.5, beta_2=0.999).get_updates(weights_d, [], d_total)\n",
    "d_train_function = K.function([real_a, real_b], [d_a_loss, d_b_loss], training_updates)\n",
    "training_updates = Adam(lr=2e-4, beta_1=0.5, beta_2=0.999).get_updates(weights_g, [], g_total)\n",
    "g_train_function = K.function([real_a, real_b], [g_a_loss, g_b_loss, cycle_loss], training_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(img, imagesize=256):\n",
    "    img = Image.open(img).convert('RGB')\n",
    "    img = img.resize((256, 256), Image.BICUBIC)\n",
    "    img = np.array(img)\n",
    "    img = img.astype(np.float32)\n",
    "    img = (img - 127.5) / 127.5\n",
    "\n",
    "    return img\n",
    "\n",
    "trainA = glob.glob('data/trainA/*')\n",
    "trainB = glob.glob('data/trainB/*')\n",
    "print(len(trainA))\n",
    "print(len(trainB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minibatch(data, batchsize=1):\n",
    "    length = len(data)\n",
    "    shuffle(data)\n",
    "    epoch = i = 0\n",
    "    tmpsize = None    \n",
    "    while True:\n",
    "        size = tmpsize if tmpsize else batchsize\n",
    "        if i+size > length:\n",
    "            i = 0\n",
    "            epoch+=1        \n",
    "        rtn = [read_image(data[j]) for j in range(i,i+size)]\n",
    "        i+=size\n",
    "        tmpsize = yield epoch, np.float32(rtn)       \n",
    "\n",
    "def minibatchAB(dataA, dataB, batchsize=1):\n",
    "    batchA=minibatch(dataA, batchsize)\n",
    "    batchB=minibatch(dataB, batchsize)\n",
    "    tmpsize = None    \n",
    "    while True:        \n",
    "        ep1, A = batchA.send(tmpsize)\n",
    "        ep2, B = batchB.send(tmpsize)\n",
    "        tmpsize = yield max(ep1, ep2), A, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(X, rows=1, image_size=256):\n",
    "    int_X = ((X*127.5+127.5).clip(0,255).astype('uint8'))\n",
    "    int_X = int_X.reshape(-1,image_size,image_size, 3)\n",
    "    int_X = int_X.reshape(rows, -1, image_size, image_size,3).swapaxes(1,2).reshape(rows*image_size,-1, 3)\n",
    "    pil_X = Image.fromarray(int_X)\n",
    "    display(pil_X)\n",
    "\n",
    "train_batch = minibatchAB(trainA, trainB, 4)\n",
    "\n",
    "_, A, B = next(train_batch)\n",
    "display_image(A)\n",
    "display_image(B)\n",
    "del train_batch, A, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagePool():\n",
    "    def __init__(self, pool_size=50):\n",
    "        self.pool_size = pool_size\n",
    "        if self.pool_size > 0:\n",
    "            self.num_imgs = 0\n",
    "            self.images = []\n",
    "\n",
    "    def query(self, images):\n",
    "        if self.pool_size == 0:\n",
    "            return images\n",
    "        \n",
    "        return_images = []\n",
    "        for image in images:\n",
    "            if self.num_imgs < self.pool_size:\n",
    "                self.num_imgs = self.num_imgs + 1\n",
    "                self.images.append(image)\n",
    "                return_images.append(image)\n",
    "            else:\n",
    "                p = uniform(0, 1)\n",
    "                if p > 0.5:\n",
    "                    random_id = randint(0, self.pool_size-1)\n",
    "                    tmp = self.images[random_id]\n",
    "                    self.images[random_id] = image\n",
    "                    return_images.append(tmp)\n",
    "                else:\n",
    "                    return_images.append(image)\n",
    "        return_images = np.stack(return_images, axis=0)\n",
    "        \n",
    "        return return_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showG(A,B):\n",
    "    def G(generated, X):\n",
    "        r = np.array([generated([X[i:i+1]]) for i in range(X.shape[0])])\n",
    "        return r.swapaxes(0,1)[:,:,0]        \n",
    "    rA = G(cycleA_generate, A)\n",
    "    rB = G(cycleB_generate, B)\n",
    "    arr = np.concatenate([A,B,rA[0],rB[0],rA[1],rB[1]])\n",
    "    display_image(arr, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "epoch = 0\n",
    "EPOCHS = 200\n",
    "DISPLAY_STEP = 50\n",
    "counter = 0\n",
    "\n",
    "train_batch = minibatchAB(trainA, trainB)\n",
    "while epoch < EPOCHS:\n",
    "    epoch, A, B = next(train_batch)\n",
    "    _,_  = d_train_function([A, B])\n",
    "    _,_, _ = g_train_function([A, B])\n",
    "    counter += 1\n",
    "    if np.mod(counter, DISPLAY_STEP) == 0:\n",
    "        clear_output()\n",
    "        print('[Epoch {}/{}][Iteration {}]'.format(epoch, EPOCHS, counter))\n",
    "        showG(A,B)\n",
    "        \n",
    "    # TODO save 2 pictures every 10 epochs\n",
    "    # TODO connect tensorboard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
